[
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "",
    "text": "In this exercise, I will use a selected module of the Shiny application for the Group Project component to fulfill the following objectives:\n\nTo evaluate and determine what are the necessary R packages needed for the Shiny application,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determined above.\n\n\n\nFor our project, we aim to create a Shiny app with user-friendly functionalities, to effectively visualize and analyze climate data.\nThe R Shiny app will consists of three modules:\n\nEDA and CDA module\nUnivariate Forecasting module\nSpatial Interpolation module\n\nFor this exercise, we will focus on the last Spatial Interpolation module. In this geospatial module, two spatial interpolation techniques are presented for user to estimate weather conditions (Rainfall or Temperature) at unmonitored locations. The module is designed to allow users to interactively adjust the inputs for each technique, providing a hands-on opportunity to explore and understand the impact of different parameters on the interpolation results."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#load-packages",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\n\npacman::p_load(gstat)\n\n\nlibrary(tmap)\n\n\npacman::p_load(tidyverse, naniar, imputeTS, DT, knitr, lubridate,\n               sf, terra, viridis, automap,\n               ggplot2, patchwork, ggthemes, ggiraph, plotly)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#import-data",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.1 Import data",
    "text": "3.1 Import data\n\nraw_weather_data &lt;- read_csv(\"data/climate_historical_daily_records.csv\")\n\nDetails of dataset:\n\n\n\n\n\n\n\n\n\nDataset\nDescription\nPeriod\nSource\n\n\n\n\nraw_weather_data\nClimate Historical Daily Records for 63 stations in Singapore\n2014-2023\nhttp://www.weather.gov.sg/climate-historical-daily/\n\n\n\nThis dataset was retrieved from the Meteorological Service Singapore site, and had some basic pre-processing steps performed in python due to the large amount of files:\n\nCombine all downloaded CSV files into one dataframe.\nPerforming cleaning to merge data of columns with slightly different names due to case sensitivity (e.g., “min” vs. “Min”)\n(‘Highest 30 Min Rainfall (mm)’, ‘Highest 30 min Rainfall (mm)’)\n(‘Highest 60 Min Rainfall (mm)’, ‘Highest 60 min Rainfall (mm)’)\n(‘Highest 120 Min Rainfall (mm)’, ‘Highest 120 min Rainfall (mm)’)\nAdd the latitude and longitude of each station to the dataframe."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-structure-with-glimpse",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-structure-with-glimpse",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.2 Check structure with glimpse()",
    "text": "3.2 Check structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 202,976\nColumns: 15\n$ Station                         &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Leba…\n$ Year                            &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 20…\n$ Month                           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Day                             &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…\n$ `Daily Rainfall Total (mm)`     &lt;chr&gt; \"0.0\", \"0.0\", \"2.2\", \"0.6\", \"10.5\", \"3…\n$ `Highest 30 Min Rainfall (mm)`  &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\"…\n$ `Highest 60 Min Rainfall (mm)`  &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\"…\n$ `Highest 120 Min Rainfall (mm)` &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\"…\n$ `Mean Temperature (°C)`         &lt;chr&gt; \"\\u0097\", \"\\u0097\", \"\\u0097\", \"\\u0097\"…\n$ `Maximum Temperature (°C)`      &lt;chr&gt; \"29.5\", \"31.7\", \"31.1\", \"32.3\", \"27.0\"…\n$ `Minimum Temperature (°C)`      &lt;chr&gt; \"24.8\", \"25.0\", \"25.1\", \"23.7\", \"23.8\"…\n$ `Mean Wind Speed (km/h)`        &lt;chr&gt; \"15.8\", \"16.5\", \"14.9\", \"8.9\", \"11.9\",…\n$ `Max Wind Speed (km/h)`         &lt;chr&gt; \"35.3\", \"37.1\", \"33.5\", \"35.3\", \"33.5\"…\n$ LAT                             &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524…\n$ LONG                            &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007…\n\n\nThere are 202, 976 rows, and 15 columns in the dataset. In the next few steps, we will drop specific columns and rows based on the project focus."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#filter-dataset-for-desired-period",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#filter-dataset-for-desired-period",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.3 Filter dataset for desired period",
    "text": "3.3 Filter dataset for desired period\nWhile the dataset contains 10 years of data from 2014 to 2023, we will focus on the most recent dataset for a 3 year period, from 2021 to 2023. This period was chosen to maximise the overall availability of data across the stations.\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  filter(Year &gt;= 2021)\nprint(paste(\"The dataset covers the period from\", min(raw_weather_data$Year, na.rm = TRUE), \"to\", max(raw_weather_data$Year, na.rm = TRUE), \".\"))\n\n[1] \"The dataset covers the period from 2021 to 2023 .\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#drop-unused-columns",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#drop-unused-columns",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.4 Drop unused columns",
    "text": "3.4 Drop unused columns\nWe will not be using all 15 columns for this project. The following columns will be dropped:\n\nHighest 30 Min Rainfall (mm)\nHighest 60 Min Rainfall (mm)\nHighest 1200 Min Rainfall (mm)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\n\n# Drop columns\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  select(-c(`Highest 30 Min Rainfall (mm)`, \n            `Highest 60 Min Rainfall (mm)`, \n            `Highest 120 Min Rainfall (mm)`,\n            `Mean Wind Speed (km/h)`,\n            `Max Wind Speed (km/h)`))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#remove-rows-for-specific-stations",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#remove-rows-for-specific-stations",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.5 Remove rows for specific Stations",
    "text": "3.5 Remove rows for specific Stations\nThe Meteorological Service Singapore also provides a file, Station Records that has some information on the availability of data for each station. After examining the station records file, we found that 41 stations had missing information for some variables. We will hence drop rows for these stations.\n\n\nshow code\n# Drop rows of 41 stations\n# Define the station names to remove\nstations_to_remove &lt;- c(\"Macritchie Reservoir\", \"Lower Peirce Reservoir\", \"Pasir Ris (West)\", \"Kampong Bahru\", \"Jurong Pier\", \"Ulu Pandan\", \"Serangoon\", \"Jurong (East)\", \"Mandai\", \"Upper Thomson\", \"Buangkok\", \"Boon Lay (West)\", \"Bukit Panjang\", \"Kranji Reservoir\", \"Tanjong Pagar\", \"Admiralty West\", \"Queenstown\", \"Tanjong Katong\", \"Chai Chee\", \"Upper Peirce Reservoir\", \"Kent Ridge\", \"Somerset (Road)\", \"Punggol\", \"Tuas West\", \"Simei\", \"Toa Payoh\", \"Tuas\", \"Bukit Timah\", \"Yishun\", \"Buona Vista\", \"Pasir Ris (Central)\", \"Jurong (North)\", \"Choa Chu Kang (West)\", \"Serangoon North\", \"Lim Chu Kang\", \"Marine Parade\", \"Choa Chu Kang (Central)\", \"Dhoby Ghaut\", \"Nicoll Highway\", \"Botanic Garden\", \"Whampoa\")\n\n# Remove rows with the specified station names\nraw_weather_data &lt;- raw_weather_data[!raw_weather_data$Station %in% stations_to_remove, ]\n\n# Print the number of stations left\nprint(sprintf(\"There were %d stations removed.There are %d stations left.\", length(stations_to_remove), n_distinct(raw_weather_data$Station)))\n\n\n[1] \"There were 41 stations removed.There are 21 stations left.\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-for-duplicates",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-for-duplicates",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.6 Check for duplicates",
    "text": "3.6 Check for duplicates\n\n\nshow code\n# Identify duplicates\nduplicates &lt;- raw_weather_data[duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")]) | duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")], fromLast = TRUE), ]\n\n# Check if 'duplicates' dataframe is empty\nif (nrow(duplicates) == 0) {\n  print(\"The combination of Station Name, Year, Month, and Day is unique.\")\n} else {\n  print(\"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\")\n  print(duplicates)\n}\n\n\n[1] \"The combination of Station Name, Year, Month, and Day is unique.\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-and-handle-missing-values",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#check-and-handle-missing-values",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.7 Check and handle missing values",
    "text": "3.7 Check and handle missing values\n\n3.7.1 First check for missing values\nMissing values in this dataset can be represented by:\n\n\\u0097\nNA\n-\n\nWe first replace these values with actual NA values:\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"\\u0097\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"NA\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"-\")))\n\nNext, we visualize the missing values in the dataset:\n\n\nshow code\nvis_miss(raw_weather_data)\n\n\n\n\n\n\n\n\n\nWe will take steps to handle the missing data.\n\n\n3.7.2 Remove Stations with significant missing data\nWe have identified two checks to make:\n\nCheck which stations have no recorded data for entire months.\nCheck which stations have more than 7 consecutive days of missing data\n\nFor both these checks, we will remove the entire station from the dataset as it would not be practical to impute such large amounts of missing values.\n\n3.7.2.1 Identify and remove Stations with no recorded data for entire months\nSome stations have no recorded data for entire months, as summarised in the table below:\n\n\nshow code\n# Create complete combination of Station, Year, and Month\nall_combinations &lt;- expand.grid(\n  Station = unique(raw_weather_data$Station),\n  Year = 2021:2023,\n  Month = 1:12\n)\n\n# Left join this with the original weather data to identify missing entries\nmissing_months &lt;- all_combinations %&gt;%\n  left_join(raw_weather_data, by = c(\"Station\", \"Year\", \"Month\")) %&gt;%\n  # Use is.na() to check for rows that didn't have a match in the original data\n  filter(is.na(Day)) %&gt;%\n  # Select only the relevant columns for the final output\n  select(Station, Year, Month)\n\n# Create a summary table that lists out the missing months\nmissing_months_summary &lt;- missing_months %&gt;%\n  group_by(Station, Year) %&gt;%\n  summarise(MissingMonths = toString(sort(unique(Month))), .groups = 'drop')\n\nkable(missing_months_summary)\n\n\n\n\n\nStation\nYear\nMissingMonths\n\n\n\n\nKhatib\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\n\nshow code\nraw_weather_data &lt;- anti_join(raw_weather_data, missing_months, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(missing_months$Station), paste(unique(missing_months$Station), collapse = \", \")))\n\n\n[1] \"The folowing 1 stations were dropped: Khatib\"\n\n\nshow code\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n\n[1] \"There are 20 stations left: \"\n\n\nshow code\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nNewton\n\n\n9\nTuas South\n\n\n10\nPasir Panjang\n\n\n11\nJurong Island\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nChangi\n\n\n15\nSeletar\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang\n\n\n\n\n\n\n\n3.7.2.2 Identify and remove Stations with excessive missing values\nIf there are any missing values, we can try to impute these missing values. However, if there are 7 or more consecutive values missing, we will remove these stations first.\n\n\nshow code\n# Define a helper function to count the number of 7 or more consecutive NAs\ncount_seven_consecutive_NAs &lt;- function(x) {\n  na_runs &lt;- rle(is.na(x))\n  total_consecutive_NAs &lt;- sum(na_runs$lengths[na_runs$values & na_runs$lengths &gt;= 7])\n  return(total_consecutive_NAs)\n}\n\n# Apply the helper function to each relevant column within grouped data\nweather_summary &lt;- raw_weather_data %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(across(-Day, ~ count_seven_consecutive_NAs(.x), .names = \"count_consec_NAs_{.col}\"), .groups = \"drop\")\n\n# Filter to keep only rows where there is at least one column with 7 or more consecutive missing values\nweather_summary_with_consecutive_NAs &lt;- weather_summary %&gt;%\n  filter(if_any(starts_with(\"count_consec_NAs_\"), ~ . &gt; 0))\n\n# View the result\nprint(sprintf(\"There are %d stations with 7 or more consecutive missing values.\", n_distinct(weather_summary_with_consecutive_NAs$Station)))\n\n\n[1] \"There are 9 stations with 7 or more consecutive missing values.\"\n\n\nshow code\n# kable(weather_summary_with_consecutive_NAs)\ndatatable(weather_summary_with_consecutive_NAs, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Details of stations with &gt;=7 missing values')\n\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\n\nshow code\nraw_weather_data &lt;- anti_join(raw_weather_data, weather_summary_with_consecutive_NAs, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(weather_summary_with_consecutive_NAs$Station), paste(unique(weather_summary_with_consecutive_NAs$Station), collapse = \", \")))\n\n\n[1] \"The folowing 9 stations were dropped: Admiralty, Clementi, Jurong Island, Marina Barrage, Paya Lebar, Semakau Island, Sembawang, Sentosa Island, Tengah\"\n\n\nshow code\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n\n[1] \"There are 11 stations left: \"\n\n\nshow code\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPulau Ubin\n\n\n2\nEast Coast Parkway\n\n\n3\nAng Mo Kio\n\n\n4\nNewton\n\n\n5\nTuas South\n\n\n6\nPasir Panjang\n\n\n7\nChoa Chu Kang (South)\n\n\n8\nChangi\n\n\n9\nSeletar\n\n\n10\nTai Seng\n\n\n11\nJurong (West)\n\n\n\n\n\n\n\n\n3.7.3 Second check for missing values\nFrom the check below we see there are still missing values in our data. We will impute these values in the next step.\n\n\nshow code\nvis_miss(raw_weather_data)\n\n\n\n\n\n\n\n\n\n\n\n3.7.4 Impute missing values\nTo handle the missing values for the remaining Stations, we will impute missing values using simple moving average from imputeTS package.\n\n3.7.4.1 Create Date column\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, Day, sep = \"-\"))) %&gt;%\n  relocate(Date, .after = 1)\n\n\n\n3.7.4.2 Using imputeTS package\n\n# Define the weather variables to loop through\nweather_variables &lt;- c(\"Daily Rainfall Total (mm)\", \"Mean Temperature (°C)\", \"Maximum Temperature (°C)\", \"Minimum Temperature (°C)\")\n\n# Ensure raw_weather_data is correctly copied to a new data frame for imputation\nweather_data_imputed &lt;- raw_weather_data\n\n# Loop through each weather variable to impute missing values\nfor(variable in weather_variables) {\n  # Convert variable to numeric, ensuring that the conversion warnings are handled if necessary\n  weather_data_imputed[[variable]] &lt;- as.numeric(as.character(weather_data_imputed[[variable]]))\n  \n  # Impute missing values using a moving average\n  weather_data_imputed &lt;- weather_data_imputed %&gt;%\n    group_by(Station) %&gt;%\n    arrange(Station, Date) %&gt;%\n    mutate(\"{variable}\" := round(na_ma(.data[[variable]], k = 7, weighting = \"simple\"), 1)) %&gt;%\n    ungroup()\n}\n\n\n\n\n3.7.5 Final visual check for missing values\n\n\nshow code\nvis_miss(weather_data_imputed)\n\n\n\n\n\n\n\n\n\n\n\n3.7.6 Add specific columns to data\nThese columns are added as they may be used in plots later.\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;% \n  mutate(Date_mine = make_date(2023, month(Date), day(Date)),\n         Month_Name = factor(months(Date), levels = month.name),\n         Week = isoweek(Date),\n         Weekday = wday(Date)) %&gt;%\n  select(1:5, Date_mine, Month_Name, Week, Weekday, everything()) # Re-order columns"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#sec-viewcleaneddataset",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#sec-viewcleaneddataset",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.8 Summary of cleaned data",
    "text": "3.8 Summary of cleaned data\n\n3.8.1 Details of stations and time period of data\n\n\nshow code\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\n\nThe time period of the dataset is from 2021-01-01 to 2023-12-31 \n\n\nshow code\nprint(sprintf(\"There are %d stations: \", n_distinct(weather_data_imputed$Station)))\n\n\n[1] \"There are 11 stations: \"\n\n\nshow code\nkable(unique(weather_data_imputed$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Stations\")\n\n\n\nList of Stations\n\n\n\nStation\n\n\n\n\n1\nAng Mo Kio\n\n\n2\nChangi\n\n\n3\nChoa Chu Kang (South)\n\n\n4\nEast Coast Parkway\n\n\n5\nJurong (West)\n\n\n6\nNewton\n\n\n7\nPasir Panjang\n\n\n8\nPulau Ubin\n\n\n9\nSeletar\n\n\n10\nTai Seng\n\n\n11\nTuas South\n\n\n\n\n\n\n\n3.8.2 Check structure with glimpse()\n\nglimpse(weather_data_imputed)\n\nRows: 12,045\nColumns: 15\n$ Station                     &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", …\n$ Date                        &lt;date&gt; 2021-01-01, 2021-01-02, 2021-01-03, 2021-…\n$ Year                        &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ Month                       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Day                         &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…\n$ Date_mine                   &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-…\n$ Month_Name                  &lt;fct&gt; January, January, January, January, Januar…\n$ Week                        &lt;dbl&gt; 53, 53, 53, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, …\n$ Weekday                     &lt;dbl&gt; 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, …\n$ `Daily Rainfall Total (mm)` &lt;dbl&gt; 94.4, 114.4, 5.2, 0.0, 0.0, 0.0, 1.6, 12.6…\n$ `Mean Temperature (°C)`     &lt;dbl&gt; 24.0, 23.0, 23.9, 25.1, 26.9, 26.9, 24.4, …\n$ `Maximum Temperature (°C)`  &lt;dbl&gt; 26.2, 24.5, 25.3, 27.9, 31.6, 30.3, 26.0, …\n$ `Minimum Temperature (°C)`  &lt;dbl&gt; 21.5, 21.6, 23.2, 23.1, 24.1, 25.1, 23.8, …\n$ LAT                         &lt;dbl&gt; 1.3764, 1.3764, 1.3764, 1.3764, 1.3764, 1.…\n$ LONG                        &lt;dbl&gt; 103.8492, 103.8492, 103.8492, 103.8492, 10…\n\n\n\n\n3.8.3 View dataset as interactive table\n\n\nshow code\ndatatable(weather_data_imputed, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Cleaned and imputed weather dataset')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#save-cleaned-data-to-.rds",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#save-cleaned-data-to-.rds",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.9 Save cleaned data to .rds",
    "text": "3.9 Save cleaned data to .rds\n\nwrite_rds(weather_data_imputed, \"data/weather_imputed_11stations.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#import-cleaned-data",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#import-cleaned-data",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "3.10 Import cleaned data",
    "text": "3.10 Import cleaned data\nThe below code can be used to import the cleaned data.\n\nweather_data &lt;- read_rds(\"data/weather_imputed_11stations.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#overview-of-exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#overview-of-exploratory-data-analysis",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "5.1 Overview of Exploratory Data Analysis",
    "text": "5.1 Overview of Exploratory Data Analysis\nThere are 4 variables in the dataset, weather_data, that we can use for time series analysis:\n\nDaily Rainfall Total (mm)\nMean Temperature (°C)\nMinimum Temperature (°C)\nMaximum Temperature (°C)\n\nFor this exercise, we will utilise Horizon Plots to visualize multiple time series data. Future work on the project may include other exploratory plots for visualizing multiple time series data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#horizon-plots",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#horizon-plots",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "5.1 Horizon Plots",
    "text": "5.1 Horizon Plots\nWe will utilise Horizon Plots to explore and visualize multiple time series data at a glance.\nHorizon plots are a visualization technique used for displaying multiple time series data. Since the data contains data across multiple years for multiple stations, it would be valuable to allow users to use horizon plots to visually explore patterns or trends across multiple time series data.\nOverview of user options:\n\nSelect daily variable to plot\nPlot across stations for different time granularity\nChoose months to plot (Compare 1 month, Compare 3 months, Compare 6 months)\nChoose years to plot (Compare 1 year, Compare 2 years, Compare 3 years)\nPlot across different time periods for a single stations\n\n\n5.1.1 Horizon Plot with reproducible code\n\n\nshow code\ncompareAcrossHorizon = \"Stations\"\nselectedYear = 2021 # Need to update below code for selection of year\nselected_var = \"Mean Temperature (°C)\"\ndate_breaks = \"3 month\"\ntitle &lt;- ifelse(compareAcrossHorizon == \"Years\",\n                paste(selected_var, \"for\", selectedStation, \"across the years 2021 to 2023\"),\n                paste(selected_var, \"for\", selectedYear, \"across station(s)\"))\n\n# Compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data %&gt;% \n  mutate(\n    outlier = between(\n      .data[[selected_var]], \n      quantile(.data[[selected_var]], 0.25, na.rm = TRUE) -\n        1.5 * IQR(.data[[selected_var]], na.rm = TRUE),\n      quantile(.data[[selected_var]], 0.75, na.rm = TRUE) +\n        1.5 * IQR(.data[[selected_var]], na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\n# ori &lt;- sum(range(cutpoints[[selected_var]]))/2\n# sca &lt;- seq(range(cutpoints[[selected_var]])[1], range(cutpoints[[selected_var]])[2], length.out = seq_length)[-seq_length/2]\n\nori &lt;- sum(range(cutpoints[[selected_var]]))/2\nsca &lt;- seq(range(cutpoints[[selected_var]])[1], range(cutpoints[[selected_var]])[2], length.out = 7)[-4]\n\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\nweather_data %&gt;% ggplot() +\n  geom_horizon(aes(x = Date,\n                   y = .data[[selected_var]],\n                   fill = after_stat(Cutpoints)),\n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(`Station`~.) +\n  theme_few() +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = date_breaks, date_labels = \"%b%y\") +\n  ggtitle(title)\n\n\n\n\n\n\n\n\n\n\n\n5.1.2 Horizon Plot of Mean Temperature (°C) across different weather stations, for 2021 - 2023\n\n\nshow code\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data %&gt;% \n  mutate(\n    outlier = between(\n      `Mean Temperature (°C)`, \n      quantile(`Mean Temperature (°C)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE),\n      quantile(`Mean Temperature (°C)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\nori &lt;- sum(range(cutpoints$`Mean Temperature (°C)`))/2\nsca &lt;- seq(range(cutpoints$`Mean Temperature (°C)`)[1], \n           range(cutpoints$`Mean Temperature (°C)`)[2], \n           length.out = 7)[-4]\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\nweather_data %&gt;% ggplot() +\n  geom_horizon(aes(x = Date,\n                   y = `Mean Temperature (°C)`,\n                   fill = after_stat(Cutpoints)),\n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(`Station`~.) +\n  theme_few() +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    # legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Mean Temperature (°C) across different weather stations (2021 - 2023)')\n\n\n\n\n\n\n\n\n\n\n\n5.1.3 Horizon Plot of Mean Temperature (°C) across different weather stations for a specified year, 2023\n\n\nshow code\n# Ensure data has Year, Month, Date column + Date_mine column\nweather_data &lt;- weather_data %&gt;% \n  mutate(Year = year(Date)) %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  mutate(Day = day(Date)) %&gt;%\n  mutate(Date_mine = make_date(2023, month(Date), day(Date)))\n\n# Filter for specified year only\nweather_data_2023 &lt;- weather_data %&gt;% \n  filter(Year == 2023) \n\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data_2023 %&gt;% \n  mutate(\n    outlier = between(\n      `Mean Temperature (°C)`, \n      quantile(`Mean Temperature (°C)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE),\n      quantile(`Mean Temperature (°C)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$`Mean Temperature (°C)`))/2\nsca &lt;- seq(range(cutpoints$`Mean Temperature (°C)`)[1], \n           range(cutpoints$`Mean Temperature (°C)`)[2], \n           length.out = 7)[-4]\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\n# Plot horizon plot\nweather_data_2023 %&gt;% ggplot() +\n  geom_horizon(aes(x = Date_mine, \n                   y = `Mean Temperature (°C)`,\n                   fill = after_stat(Cutpoints)), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(~Station ~ .) +\n  theme_few() +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand = c(0, 0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab('Date') +\n  ggtitle('Mean Temperature (°C) for the year 2023',\n          'across the stations')\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Horizon Plot of Mean Temperature (°C) For Ang Mo Kio across the years\n\n\nshow code\n# Step 0: Filter for specified station only \nang_mo_kio_data &lt;- weather_data %&gt;% \n  filter(Station == \"Seletar\")\n\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- ang_mo_kio_data %&gt;% \n  mutate(\n    outlier = between(\n      `Mean Temperature (°C)`, \n      quantile(`Mean Temperature (°C)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE),\n      quantile(`Mean Temperature (°C)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$`Mean Temperature (°C)`))/2\nsca &lt;- seq(range(cutpoints$`Mean Temperature (°C)`)[1], \n           range(cutpoints$`Mean Temperature (°C)`)[2], \n           length.out = 7)[-4]\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\n# Step 2: Ensure data has Year, Month, Date column. Also create a Date_mine column for comparing across years\nang_mo_kio_data &lt;- ang_mo_kio_data %&gt;% \n  mutate(Year = year(Date)) %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  mutate(Day = day(Date)) %&gt;%\n  mutate(Date_mine = make_date(2023, month(Date), day(Date)))\n\n# Step 3: Plot horizon plot\nang_mo_kio_data %&gt;% ggplot() +\n  geom_horizon(aes(x = Date_mine, \n                   y = `Mean Temperature (°C)`,\n                   fill = after_stat(Cutpoints)), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(~Year ~ .) +\n  theme_few() +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand = c(0, 0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab('Date') +\n  ggtitle('Mean Temperature (°C) For Ang Mo Kio',\n          'across the years 2021 to 2023')\n\n\n\n\n\n\n\n\n\n\n\n5.1.5 Horizon Plot of Mean Temperature (°C) across average of all weather stations from 2021 to 2023\n\n\nshow code\n# Step 0: Compute average of Mean Temperature (°C) across all stations\nweather_data_all_stations &lt;- weather_data %&gt;%\n  group_by(Date) %&gt;%\n  summarise(`Mean Temperature (°C)` = mean(`Mean Temperature (°C)`))\n\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data_all_stations %&gt;% \n  mutate(\n    outlier = between(\n      `Mean Temperature (°C)`, \n      quantile(`Mean Temperature (°C)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE),\n      quantile(`Mean Temperature (°C)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Mean Temperature (°C)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$`Mean Temperature (°C)`))/2\nsca &lt;- seq(range(cutpoints$`Mean Temperature (°C)`)[1], \n           range(cutpoints$`Mean Temperature (°C)`)[2], \n           length.out = 7)[-4]\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\n# Step 2: Ensure data has Year, Month, Date column. Also create a Date_mine column for comparing across years\nweather_data_all_stations &lt;- weather_data_all_stations %&gt;% \n  mutate(Year = year(Date)) %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  mutate(Day = day(Date)) %&gt;%\n  mutate(Date_mine = make_date(2023, month(Date), day(Date)))\n\n# Step 3: Plot horizon plot\nweather_data_all_stations %&gt;% ggplot() +\n  geom_horizon(aes(x = Date_mine, \n                   y = `Mean Temperature (°C)`,\n                   fill = after_stat(Cutpoints)), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(~Year ~ .) +\n  theme_few() +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand = c(0, 0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab('Date') +\n  ggtitle('Mean Temperature (°C) across across all weather stations', \n          'from 2021 to 2023')\n\n\n\n\n\n\n\n\n\n\n\n5.1.6 Horizon Plot of Daily Rainfall Total across all weather stations from 2021 to 2023\nThis plot may not make sense as we may need to sum up rainfall for each day across all weather stations first before plotting.\n\n\nshow code\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data %&gt;% \n  mutate(\n    outlier = between(\n      `Daily Rainfall Total (mm)`, \n      quantile(`Daily Rainfall Total (mm)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Daily Rainfall Total (mm)`, na.rm = TRUE),\n      quantile(`Daily Rainfall Total (mm)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Daily Rainfall Total (mm)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$`Daily Rainfall Total (mm)`))/2\nsca &lt;- seq(range(cutpoints$`Daily Rainfall Total (mm)`)[1], \n           range(cutpoints$`Daily Rainfall Total (mm)`)[2], \n           length.out = 7)[-4]\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\n\n# Step 2: Ensure data has Year, Month, Date column. Also create a Date_mine column for comparing across years\nweather_data &lt;- weather_data %&gt;% \n  mutate(Year = year(Date)) %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  mutate(Day = day(Date)) %&gt;%\n  mutate(Date_mine = make_date(2023, month(Date), day(Date)))\n\n# Step 3: Plot horizon plot\nweather_data %&gt;% ggplot() +\n  geom_horizon(aes(x = Date_mine, \n                   y = `Daily Rainfall Total (mm)`,\n                   fill = after_stat(Cutpoints)), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(~Year ~ .) +\n  theme_few() +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand = c(0, 0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab('Date') +\n  ggtitle('Daily Rainfall Total across all weather stations', \n          'from 2021 to 2023')\n\n\n\n\n\n\n\n\n\n\n\n5.1.7 Horizon Plot of Daily Rainfall Total (mm) across all the stations for a specified year\n\n\nshow code\n# Ensure data has Year, Month, Date column\nweather_data &lt;- weather_data %&gt;% \n  mutate(Year = year(Date)) %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  mutate(Day = day(Date)) %&gt;%\n  mutate(Date_mine = make_date(2023, month(Date), day(Date)))\n\n# Filter for specified year only\nweather_data_2023 &lt;- weather_data %&gt;% \n  filter(Year == 2023)\n\n# Step 1: compute origin and  horizon scale cutpoints: \ncutpoints &lt;- weather_data_2023 %&gt;% \n  mutate(\n    outlier = between(\n      `Daily Rainfall Total (mm)`, \n      quantile(`Daily Rainfall Total (mm)`, 0.25, na.rm = TRUE) -\n        1.5 * IQR(`Daily Rainfall Total (mm)`, na.rm = TRUE),\n      quantile(`Daily Rainfall Total (mm)`, 0.75, na.rm = TRUE) +\n        1.5 * IQR(`Daily Rainfall Total (mm)`, na.rm = TRUE))) %&gt;% \n  filter(outlier)\n\nori &lt;- sum(range(cutpoints$`Daily Rainfall Total (mm)`))/2\nsca &lt;- seq(range(cutpoints$`Daily Rainfall Total (mm)`)[1], \n           range(cutpoints$`Daily Rainfall Total (mm)`)[2], \n           length.out = 7)[-4]\n\nori &lt;- round(ori, 2) # The origin, rounded to 2 decimal places\nsca &lt;- round(sca, 2) # The horizon scale cutpoints\n\n# Plot horizon plot\nweather_data_2023 %&gt;% ggplot() +\n  geom_horizon(aes(x = Date_mine, \n                   y = `Daily Rainfall Total (mm)`,\n                   fill = after_stat(Cutpoints)), \n               origin = ori, horizonscale = sca) +\n  scale_fill_hcl(palette = 'RdBu', reverse = T) +\n  facet_grid(~Station ~ .) +\n  theme_few() +\n  theme(\n    panel.spacing.y = unit(0, \"lines\"),\n    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand = c(0, 0), \n               date_breaks = \"1 month\", \n               date_labels = \"%b\") +\n  xlab('Date') +\n  ggtitle('Daily Rainfall Total (mm) for the year 2023',\n          'across the stations')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#overview-1",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#overview-1",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "6.1 Overview",
    "text": "6.1 Overview\nClustering is the practice of finding hidden patterns or similar groups in data.\nTo perform time series clustering, we will use the function tsclust from dtwclust.\nhttps://cran.r-project.org/web/packages/dtwclust/vignettes/dtwclust.pdf\nWe will divide cluster analysis into the following parts:\n\nFormat data into list of series for input to clustering function\nChoosing the clustering method: “partitional”, “hierarchical”, “tadpole” or “fuzzy”\nChoosing distance computation: Ignored for type = “tadpole”.\nDetermining a measure to quantify the similarity between observations\nSelecting the desired number of clusters"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#clustering-of-stations",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#clustering-of-stations",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "6.2 Clustering of stations",
    "text": "6.2 Clustering of stations\nWe will use the variable temp_data , and perform cluster analysis of time series of daily temperature readings from different weather stations for the same period.\n\n6.2.1 Format data into list of series\nUsers should be allowed to cluster by:\n\nStations, for multiple stations and multiple years\nMonths, for a single station and a given year\n\n\nFor a single selected station and year, by monthsFor multiple stations and multiple years, by station\n\n\n\n\nshow code\n# Extract the target variable, temperature data into a variable\ntemp_data &lt;- weather_data %&gt;%\n  select(c(Station, Date, Year, Month, Month_Name, Day, `Mean Temperature (°C)`))\n\n# Filter for station(s) and year(s) e.g., \"Changi\", for 2023\nstations_selected = \"Changi\"\nyears_selected = \"2021\"\nstation_temp_data &lt;- temp_data %&gt;% \n  filter(Station %in% stations_selected) %&gt;%\n  filter(Year %in% years_selected)\n\n# Ensure the data is ordered by Month_Name and by Date\nstation_temp_data &lt;- station_temp_data %&gt;%\n  arrange(Month_Name, Date)\n\n# Format data into list of series, by Month_Name\nlist_of_series &lt;- split(station_temp_data$`Mean Temperature (°C)`, station_temp_data$Month_Name)\n\n\n\n\n\n\nshow code\n# Extract the target variable, temperature data into a variable\ntemp_data &lt;- weather_data %&gt;%\n  select(c(Station, Date, Year, Month, Day, `Mean Temperature (°C)`))\n\n# Filter for all stations and years \nstations_selected = unique(weather_data$Station) # note: not station_selected\nyears_selected = unique(weather_data$Year) # note: not stations_selected\nstation_temp_data &lt;- temp_data %&gt;% \n  filter(Station %in% stations_selected) %&gt;%\n  filter(Year %in% years_selected)\n\n\n# Group-wise (Station-by-Station) Normalization, applying Min-Max scaling within each station group\nstation_temp_data &lt;- station_temp_data %&gt;%\n  group_by(Station) %&gt;%\n  mutate(Normalized_Temp = (`Mean Temperature (°C)` - min(`Mean Temperature (°C)`, na.rm = TRUE)) / \n                            (max(`Mean Temperature (°C)`, na.rm = TRUE) - min(`Mean Temperature (°C)`, na.rm = TRUE))) %&gt;%\n  ungroup()\n\n\n# Ensure the data is ordered by Station and by Date\nstation_temp_data &lt;- station_temp_data %&gt;%\n  arrange(Station, Date)\n\n# Format data into list of series, by Station\nlist_of_series &lt;- split(station_temp_data$Normalized_Temp, station_temp_data$Station)\n\n\n\n\n\n\n\n6.2.2 Exploring clustering methods\n\n6.2.2.1 Hierarchical\nAssume clustering for several stations across 2021 - 2023.\n\n\nshow code\nn_cluster = 2 # Number of desired clusters. Should not show if cluster_type == \"partitional\"\ncluster_type = \"hierarchical\" #  \"partitional\", \"hierarchical\", \"tadpole\" or \"fuzzy\"\ndistance = \"dtw_basic\" # Ignored for type = \"tadpole\"\ncontrol = hierarchical_control(method = \"complete\") \n\nc &lt;- tsclust(series = list_of_series, \n        type = cluster_type,  \n        k = n_cluster, \n        distance = distance, \n        control = control\n        )\n\np &lt;- fviz_dend(c, k = n_cluster, # Cut in n_cluster groups\n          cex = 0.6, # label size\n          k_colors = c(\"jco\"),\n          color_labels_by_k = FALSE,  # color labels by groups\n          rect_border = \"jco\",\n          rect = TRUE,\n          rect_fill = TRUE,\n          horiz = TRUE)\np\n\n\n\n\n\n\n\n\n\nVarying number of desired clusters, k, produces the following:\n&lt;to be updated&gt;\nKeeping k at x and varying the distance computation produces the following:\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-1-horizon-plot",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-1-horizon-plot",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "8.1 Tab 1: Horizon Plot",
    "text": "8.1 Tab 1: Horizon Plot\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-2-clustering",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-2-clustering",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "8.2 Tab 2: Clustering",
    "text": "8.2 Tab 2: Clustering\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-3-forecasting",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#tab-3-forecasting",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "8.3 Tab 3: Forecasting",
    "text": "8.3 Tab 3: Forecasting\n&lt;to be updated&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "",
    "text": "ISSS608 Visual Analytics and Applications\nWelcome to my portfolio for the Visual Analytics and Applications course, taught by Prof. Kam Tin Seong. This website is a collection of exercises and assignments completed throughout the course."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html",
    "title": "In-class Exercise 7",
    "section": "",
    "text": "Objective of this exercise is to create interpolation for rainfall data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#overview",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#overview",
    "title": "In-class Exercise 7",
    "section": "",
    "text": "Objective of this exercise is to create interpolation for rainfall data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#load-libraries",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#load-libraries",
    "title": "In-class Exercise 7",
    "section": "Load libraries",
    "text": "Load libraries\n\npacman::p_load(sf, \n               terra, \n               gstat,# used for interpolation\n               tmap, \n               viridis, \n               tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#import-data",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#import-data",
    "title": "In-class Exercise 7",
    "section": "Import data",
    "text": "Import data\nRead in aspatial data, where latitude and longitude of the data is provided for each station:\n\nrfstations &lt;- read_csv(\"data/aspatial/RainfallStation.csv\")\n\n\nglimpse(rfstations)\n\nRows: 63\nColumns: 3\n$ Station   &lt;chr&gt; \"Admiralty\", \"Admiralty (West)\", \"Ang Mo Kio\", \"Boon Lay (Ea…\n$ Latitude  &lt;dbl&gt; 1.4439, 1.4582, 1.3764, 1.3302, 1.3275, 1.3087, 1.3837, 1.38…\n$ Longitude &lt;dbl&gt; 103.7854, 103.7953, 103.8492, 103.7205, 103.7042, 103.8180, …\n\n\nRead in attribute data and select for desired variables:\n\nrfdata&lt;- read_csv(\"data/aspatial/DAILYDATA_202402.csv\") %&gt;% \n  select(c(1,5)) %&gt;% # select column 1 to 5\n  group_by(Station) %&gt;% # Group by rainfall station\n  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`)) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#data-preparation",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#data-preparation",
    "title": "In-class Exercise 7",
    "section": "Data preparation",
    "text": "Data preparation\nDo a left join to add the latitude and longitude to our data.\n\nrfdata &lt;- rfdata %&gt;%\n  left_join(rfstations)\n\nMake it spatial data:\n\nrfdata_sf &lt;- st_as_sf(rfdata,\n                      coords = c(\"Longitude\", # X axis must be called first \n                                 \"Latitude\"),\n                      crs = 4236) %&gt;% # Y axis\n              st_transform(crs = 3414) # To project this into SVY21\n\nUse tmap to plot\n\n# This is a shape file, read in with st_read\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\spacebun\\ISSS608-VAA\\In-class_Ex\\In-class_Ex7\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nNotice it has a MULTIPOLYGON for the geometry column:\n\nWithin each there are multple polygon pairs:\n\nUse tmap function:\n\ntmap_options(check.and.fix = TRUE) # Some geo data may be topological data. Use this code to fix topo error without changing the data. \ntmap_mode(\"view\") # Make your map interactive\n\n# Instead of using polygon we use tm_shape\ntm_shape(mpsz2019) + # Plot boundary map\n  tm_borders() +\n  tm_shape(rfdata_sf) + # Plot rainfall station \n  tm_dots(col = \"MONTHSUM\") # Use color to differentiate the total rainfall data\n\n\n\n\ntmap_mode(\"plot\")\n\nYou can call tm_polygon() and put the fill or you can do tm_fill(). (for your consideration\nIn order to generate interpolation, we need a raster layer. We need to define the number of cols and rows in this later.\n\nmpsz2019\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nInputs required for raster layer:\n\ncalculate difference between xmax, xmin and ymax, ymin\nchoose resolutions (e.g. 50m by 50m)\n\nUse these inputs to calculate the number of rows and number columns:\n\nnrows = (ymax - ymin)/res\nncol = (xmax - xmin)/res\n\nFront end user sees the option to adjust resolution (res) of the grid.\ntake ymax - ymin divided by the raster grid resolution (e.g. 50 meters or 100 meters)\nWe will create this raster layer:\n\n# Create a raster layer, grid,  from an existing spatial object mpsz2019\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = 690, # (ymax - ymin)/50 (where 50 is chosen res)\n                   ncols = 1075) # (xmax - xmin)/50 (where 50 is chosen res)\n\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n\n\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop,mpsz2019) # Filter to only only includes points within mpsz2019"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#method-1-inverse-distance-weighted-interpolation",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#method-1-inverse-distance-weighted-interpolation",
    "title": "In-class Exercise 7",
    "section": "Method 1: inverse distance weighted interpolation",
    "text": "Method 1: inverse distance weighted interpolation\n\nres &lt;- gstat(formula = MONTHSUM ~ 1, # specify  dependent variable\n             locations = rfdata_sf,\n             nmax= 15, # number of nearest neighbors considered for interpolation. Parameter to expose for UI\n             set = list(idp = 0))\n\n# Predict values at new locations (coop) based on the spatial data (rfdata_sf)\nresp &lt;- predict(res,coop)\n\n[inverse distance weighted interpolation]\n\n# Extract x and y coordinates and the predicted values into resp\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\n\n# Predictions are rasterized over a predefined grid, using the mean of predictions where multiple values fall into a single grid cell\n# This results in a raster layer pred representing spatially interpolated values of MONTHSUM.\npred &lt;- terra:: rasterize(resp, grid, # resp$pred contains the spatially interpolated variables. grid is raster layer.\n                         field=\"pred\",\n                         fun=\"mean\")\n\nPlot the result\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) +\n  tm_raster(alpha=0.6,\n            palette = \"viridis\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#method-2-ordinary-kriging",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#method-2-ordinary-kriging",
    "title": "In-class Exercise 7",
    "section": "Method 2: ordinary kriging",
    "text": "Method 2: ordinary kriging\nVariogram model, no covariates\nWe are going to use three parameters of the gstat function:\n\nformula—The prediction “formula” specifying the dependent and the independent variables (covariates)\ndata—The calibration data\nmodel—The variogram model\n\n\nv &lt;- variogram(log(MONTHSUM) ~ 1,\n               data = rfdata_sf)\nplot(v)\n\n\n\n\n\n\n\n\n\nfv &lt;- fit.variogram(object = v,\n                    model = vgm(psill = 0.5, model = \"Sph\",\n                                range = 900, nugget = 0.1))\n\nfv\n\n  model psill range\n1   Nug   0.1     0\n2   Sph   0.5   900\n\nplot(v, fv, cex = 1.5)\n\n\n\n\n\n\n\n\n\nk &lt;- gstat(formula = log(MONTHSUM) ~ 1,\n           data = rfdata_sf,\n           model = fv)\n\n\nresp &lt;- predict(k,coop)\n\n[using ordinary kriging]\n\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\nkpred &lt;- terra::rasterize(resp, grid,\n                          field = \"pred\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred) +\n  tm_raster(alpha = 0.6,\n            palette = \"viridis\")\n\n\n\n\n\n\n\n\nYou don’t need to expose every option."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#data-preparation-1",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#data-preparation-1",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "8.1 Data Preparation",
    "text": "8.1 Data Preparation\nDesign considerations for user control:\n\nUse radioButtons function to select only one variable (“Daily Rainfall Total (mm)”, “Mean Temperature (°C)”)\nUse radioButtons function to select only one type of time window\nThis function should be conditional.\n\nFirst, read in shape file for Singapore. This step should be done before UI and server code.\n\n# This is a shape file, read in with st_read\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\spacebun\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nNext, aggregate weather data for selected variable and time window\nFor rainfall, we should aggregate by computing sum of rainfall for the month. For temperature, we should aggregate by computing average temperature per month.\n\n# Indicate user variable\nselected_var &lt;- \"Daily Rainfall Total (mm)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"January\")\nselected_year &lt;- c(\"2021\")\n\n# Create tbl for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(selected_var == \"Daily Rainfall Total (mm)\") {\n                sum(.data[[selected_var]], na.rm = TRUE)\n              } else {\n                mean(.data[[selected_var]], na.rm = TRUE)\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data,\n                      coords = c(\"LONG\", # X axis  \n                                 \"LAT\"),\n                      crs = 4236) %&gt;% # Y axis\n              st_transform(crs = 3414) # To project this into SVY21\n\n# Plot variable with tmap\ntmap_options(check.and.fix = TRUE) # Use this code to fix topo error without changing the data. \ntmap_mode(\"view\") # Make map interactive\n\n\ntm_shape(mpsz2019) + # Plot boundary map\n  tm_borders() +\n  tm_shape(variable_data_sf) + # Plot station \n  tm_dots(col = \"MonthlyValue\") # Use color to differentiate\n\n\n\n\ntmap_mode(\"plot\") # Change mode back\n\n\n# Create Raster Data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input\n\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\n\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#method-1-inverse-distance-weighted-interpolation",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#method-1-inverse-distance-weighted-interpolation",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "8.2 Method 1: inverse distance weighted interpolation",
    "text": "8.2 Method 1: inverse distance weighted interpolation\n\n8.2.1 Varying nmax\n\nnmax = 1nmax = 3\n\n\n\n\nCode\n# Set value\nnmax = 1\n\n# Create gstat object\nres &lt;- gstat(formula = MonthlyValue ~ 1, # specify  dependent variable\n             locations = variable_data_sf,\n             nmax = nmax, # number of nearest neighbors considered for interpolation. Parameter to expose for UI\n             set = list(idp = 0))\n\n# Predict values at new locations (coop) based on the spatial data (rfdata_sf)\nresp &lt;- predict(res,coop)\n\n\n[inverse distance weighted interpolation]\n\n\nCode\n# Plot The Result\n\n# Extract x and y coordinates and the predicted values into resp\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\n\n# Predictions are rasterized over a predefined grid, using the mean of predictions where multiple values fall into a single grid cell\n# This results in a raster layer pred representing spatially interpolated values of MONTHSUM.\npred &lt;- terra:: rasterize(resp, grid, # resp$pred contains the spatially interpolated variables. grid is raster layer.\n                         field=\"pred\",\n                         fun=\"mean\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) +\n  tm_raster(alpha=0.6,\n            palette = \"viridis\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Set value\nnmax = 3\n\n# Create gstat object\nres &lt;- gstat(formula = MonthlyValue ~ 1, # specify  dependent variable\n             locations = variable_data_sf,\n             nmax = nmax, # number of nearest neighbors considered for interpolation. Parameter to expose for UI\n             set = list(idp = 0))\n\n# Predict values at new locations (coop) based on the spatial data (rfdata_sf)\nresp &lt;- predict(res,coop)\n\n\n[inverse distance weighted interpolation]\n\n\nCode\n# Plot The Result\n\n# Extract x and y coordinates and the predicted values into resp\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\n\n# Predictions are rasterized over a predefined grid, using the mean of predictions where multiple values fall into a single grid cell\n# This results in a raster layer pred representing spatially interpolated values of MONTHSUM.\npred &lt;- terra:: rasterize(resp, grid, # resp$pred contains the spatially interpolated variables. grid is raster layer.\n                         field=\"pred\",\n                         fun=\"mean\")\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) +\n  tm_raster(alpha=0.6,\n            palette = \"viridis\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#clustering-and-group-forecasting-module",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#clustering-and-group-forecasting-module",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "9.1 Clustering and Group Forecasting module",
    "text": "9.1 Clustering and Group Forecasting module\nThis module will contain three tabs:\n\nHorizon Plot\nTime Series Clustering\nForecasting Grouped Time Series\n\n\n9.1.1 Tab 1: Horizon Plot\n&lt;to be updated&gt;\n\n\n\n9.1.2 Tab 2: Time Series Clustering\n&lt;to be updated&gt;\n\n\n\n9.1.3 Tab 3: Forecasting Grouped Time Series\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#geospatial-module",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#geospatial-module",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "9.2 Geospatial Module",
    "text": "9.2 Geospatial Module\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#spatial-interpolation-module-1",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#spatial-interpolation-module-1",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "9.2 Spatial Interpolation Module",
    "text": "9.2 Spatial Interpolation Module\n&lt;to be updated&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#project-details",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#project-details",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "",
    "text": "For our project, we aim to create a Shiny app with user-friendly functionalities, to effectively visualize and analyze climate data.\nThe R Shiny app will consists of three modules:\n\nEDA and CDA module\nUnivariate Forecasting module\nSpatial Interpolation module\n\nFor this exercise, we will focus on the last Spatial Interpolation module. In this geospatial module, two spatial interpolation techniques are presented for user to estimate weather conditions (Rainfall or Temperature) at unmonitored locations. The module is designed to allow users to interactively adjust the inputs for each technique, providing a hands-on opportunity to explore and understand the impact of different parameters on the interpolation results."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#prototype-module-report",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#prototype-module-report",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "4.1 Prototype module report",
    "text": "4.1 Prototype module report\n\n4.1.1 Read in shape file\nFirst, read in planning subzone boundary data (shape file) for Singapore.\nThis step should be done before running UI and server code.\n\nmpsz2019 &lt;- st_read(dsn = \"data/geospatial\",## This is a shape file, read in with st_read\n                    layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\spacebun\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n4.1.2 Data preparation, Rainfall for one-month\nWe will first focus on Rainfall data over a one-month period, assessing how various model parameters influence this variable.\nThe code chunk below selects monthly Rainfall data for analysis, and aggregates it to compute monthly totals or averages for a specific year and month.\n\n\nshow code\n# User-defined criteria\nselected_var &lt;- \"Daily Rainfall Total (mm)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\ntime_resolution &lt;- \"Monthly\" # Options: \"Daily\", \"Monthly\", \"Yearly\"\nselected_date &lt;- \"2023-02-15\" # To be single select and reactive (only show if Daily)\nselected_month &lt;- c(\"February\") # To be single select and reactive (only show if Month)\nselected_year &lt;- c(\"2023\") # To be single select and reactive (only show if Month or Year)\ninterpolation_method &lt;- \"IDW\"\n\n# Adjusting filter based on time_resolution\nif (time_resolution == \"Daily\") {\n  # Filter for a specific day, assuming Date is in YYYY-MM-DD format\n  variable_data &lt;- weather_data %&gt;%\n    filter(Date == as.Date(selected_date))\n} else if (time_resolution == \"Monthly\") {\n  # Filter for a specific month\n  variable_data &lt;- weather_data %&gt;%\n    filter(Year == selected_year,\n           Month_Name == selected_month)\n} else if (time_resolution == \"Yearly\") {\n  # Filter for an entire year\n  variable_data &lt;- weather_data %&gt;%\n    filter(Year == selected_year)\n}\n\n# Group and summarise data, selecting for the correctly variable\nvariable_data &lt;- variable_data %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # Sum or average based on the variable\n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE)\n              }, .groups = 'drop')\n\n\n\n\nshow code\n# User-defined criteria\n# Selecting variable\nselected_var &lt;- \"Daily Rainfall Total (mm)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\n# Selecting time period\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\ninterpolation_method &lt;- \"IDW\"\n\n# Create table for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Visualize variable with tmap\ntmap_options(check.and.fix = TRUE) # Use this code to fix topo error without changing the data. \ntmap_mode(\"view\") # Make map interactive\ntm_shape(mpsz2019) + # Plot boundary map\n  tm_borders() +\ntm_shape(variable_data_sf) +\n  tm_dots(col = 'MonthlyValue') # Use color to differentiate\n\n\n\n\n\n\nshow code\ntmap_mode(\"plot\") # Change mode back\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n\n\n4.1.2.1 \n\n\n\n\n4.1.3 Method 1: Inverse Distance Weighted interpolation\n\n4.1.3.1 Interpolation for specific month\nWe first focus on interpolating data using IDW method for a specified month.\nFor rainfall, we should aggregate by computing sum of rainfall for the month. For temperature, we should aggregate by computing average temperature per month.\n\nDaily Rainfall Total (mm)Mean Temperature (°C)\n\n\n\n\nshow code\n# IDW Method\nnmax = 3 # Set value\n# Create gstat object\nres &lt;- gstat(formula = MonthlyValue ~ 1, # specify  dependent variable\n             locations = variable_data_sf,\n             nmax = nmax, # number of nearest neighbors considered for interpolation. Parameter to expose for UI\n             set = list(idp = 0))\n# Predict values at new locations (coop) based on the spatial data (rfdata_sf)\nresp &lt;- predict(res,coop)\n\n\n[inverse distance weighted interpolation]\n\n\nshow code\n# Plot The Result\n# Extract x and y coordinates and the predicted values into resp\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n# Predictions are rasterized over a predefined grid, using the mean of predictions where multiple values fall into a single grid cell\n# This results in a raster layer pred representing spatially interpolated values\npred &lt;- terra:: rasterize(resp, grid, # resp$pred contains the spatially interpolated variables. grid is raster layer.\n                         field=\"pred\",\n                         fun=\"mean\")\n# map the interpolated variable raster, pred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\nVarying nmax produced the following results:\n\n\n\n\n\nshow code\n# Indicate user variable\nselected_var &lt;- \"Mean Temperature (°C)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\n\n# Create tbl for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Visualize variable with tmap\ntmap_options(check.and.fix = TRUE) # Use this code to fix topo error without changing the data. \ntmap_mode(\"view\") # Make map interactive\ntm_shape(mpsz2019) + # Plot boundary map\n  tm_borders() +\ntm_shape(variable_data_sf) +\n  tm_dots(col = 'MonthlyValue') # Use color to differentiate\n\n\n\n\n\n\nshow code\ntmap_mode(\"plot\") # Change mode back\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n# IDW Method\nnmax = 3 # Set value\n# Create gstat object\nres &lt;- gstat(formula = MonthlyValue ~ 1, # specify  dependent variable\n             locations = variable_data_sf,\n             nmax = nmax, # number of nearest neighbors considered for interpolation. Parameter to expose for UI\n             set = list(idp = 0))\n# Predict values at new locations (coop) based on the spatial data (rfdata_sf)\nresp &lt;- predict(res,coop)\n\n\n[inverse distance weighted interpolation]\n\n\nshow code\n# Plot The Result\n# Extract x and y coordinates and the predicted values into resp\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n# Predictions are rasterized over a predefined grid, using the mean of predictions where multiple values fall into a single grid cell\n# This results in a raster layer pred representing spatially interpolated values\npred &lt;- terra:: rasterize(resp, grid, # resp$pred contains the spatially interpolated variables. grid is raster layer.\n                         field=\"pred\",\n                         fun=\"mean\")\n# map the interpolated variable raster, pred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(pred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\nVarying nmax produced the following results:\n\n\n\n\n\n\n\n4.1.4 Method 2: Kriging\nKriging can be understood as a two-step process:\n\nfirst, the spatial covariance structure of the sampled points is determined by fitting a variogram; and\nsecond, weights derived from this covariance structure are used to interpolate values for unsampled points or blocks across the spatial field.\n\nThe below code chunk show the available variogram models in gstat.\n\nshow.vgms(par.strip.text = list(cex = 0.75))\n\n\n\n\n\n\n\n\n\nDaily Rainfall Total (mm)Mean Temperature (°C)\n\n\nData Prep\n\n\nshow code\n# Indicate user variable\nselected_var &lt;- \"Daily Rainfall Total (mm)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\ninterpolation_method &lt;- \"IDW\"\n\n# Create table for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n\nThis is the “experimental” variogram that should be shown to user, for user to assess what variables to adjust when fitting the variogram.\n\n\nshow code\nv &lt;- variogram(MonthlyValue ~ 1, \n               data = variable_data_sf)\nplot(v, cex = 1.5) # Experimental plot that should be shown to user\n\n\n\n\n\n\n\n\n\nThe below code chunk is used to tweak the fitted variogram:\n\n\nshow code\n# The different parameters have been tweaked and the results are presented below. \n# User will choose based on below variables \nfv &lt;- fit.variogram(object = v,\n                    model = vgm(psill = 5, model = \"Gau\", range = 8000, nugget = 0.1))\n\nfv\n\n\n  model      psill    range\n1   Nug 0.04179119    0.000\n2   Gau 5.06639147 7830.625\n\n\nshow code\nplot(v, fv, cex = 1.5) #  visualise how well the observed data fit the model by plotting fv \n\n\n\n\n\n\n\n\n\nFinal surface map\n\n\nshow code\n# perform spatial interpolation by using the newly derived model \nk &lt;- gstat(formula = MonthlyValue ~ 1,\n           data = variable_data_sf,\n           model = fv)\n\n# estimate the unknown grids\nresp &lt;- predict(k,coop)\n\n\n[using ordinary kriging]\n\n\nshow code\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\n# create a raster surface data object\nkpred &lt;- terra::rasterize(resp, grid,\n                          field = \"pred\")\n\n# map the interpolated variable raster, kpred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nData Prep:\n\n\nshow code\n# Indicate user variable\nselected_var &lt;- \"Mean Temperature (°C)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\ninterpolation_method &lt;- \"IDW\"\n\n# Create table for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n\nThis is the “experimental” variogram that should be shown to user, for user to assess what variables to adjust when fitting the variogram.\n\n\nshow code\nv &lt;- variogram(MonthlyValue ~ 1, \n               data = variable_data_sf)\nplot(v, cex = 1.5) # Experimental plot that should be shown to user\n\n\n\n\n\n\n\n\n\nThe below code chunk is used to tweak the fitted variogram:\n\n\nshow code\n# The different parameters have been tweaked and the results are presented below. \n# User will choose based on below variables \nfv &lt;- fit.variogram(object = v,\n                    model = vgm(psill = 5, model = \"Gau\", range = 5000, nugget = 0.1))\n\nfv\n\n\n  model     psill    range\n1   Nug 0.0000000    0.000\n2   Gau 0.1529218 6992.675\n\n\nshow code\nplot(v, fv, cex = 1.5) #  visualise how well the observed data fit the model by plotting fv \n\n\n\n\n\n\n\n\n\nFinal surface map\n\n\nshow code\n# perform spatial interpolation by using the newly derived model \nk &lt;- gstat(formula = MonthlyValue ~ 1,\n           data = variable_data_sf,\n           model = fv)\n\n# estimate the unknown grids\nresp &lt;- predict(k,coop)\n\n\n[using ordinary kriging]\n\n\nshow code\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\n# create a raster surface data object\nkpred &lt;- terra::rasterize(resp, grid,\n                          field = \"pred\")\n\n# map the interpolated variable raster, kpred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nWhen varying model option, there was noticeable variation in the final surface map:\n\nWhen varying psill option for different models, some models showed different surface maps while others looked similar:\n\n\nWhen varying range option while keeping the other options static, there were different surface maps:\n\n\n4.1.4.1 Automatic variogram modelling\nBeside using gstat to perform variogram modelling manually, autofirVariogram() of automap package can be used to perform varigram modelling.\n\nDaily Rainfall Total (mm)Mean Temperature (°C)\n\n\nData Prep:\n\n\nshow code\n# Indicate user variable\nselected_var &lt;- \"Daily Rainfall Total (mm)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\ninterpolation_method &lt;- \"IDW\"\n\n# Create table for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n\nAuto fit variogram:\n\n\nshow code\nv_auto &lt;- autofitVariogram(MonthlyValue ~ 1, \n                           variable_data_sf)\nplot(v_auto)\n\n\n\n\n\n\n\n\n\nshow code\nv_auto\n\n\n$exp_var\n  np      dist    gamma dir.hor dir.ver   id\n1 11  7150.576 1528.562       0       0 var1\n2  5 11075.718 1076.144       0       0 var1\n3 11 13965.947 2658.518       0       0 var1\n\n$var_model\n  model     psill    range\n1   Nug 1491.0299    0.000\n2   Exp  693.4758 8155.059\n\n$sserr\n[1] 0.08453662\n\nattr(,\"class\")\n[1] \"autofitVariogram\" \"list\"            \n\n\nFinal surface map:\n\n\nshow code\n# perform spatial interpolation by using the newly derived model \nk &lt;- gstat(formula = MonthlyValue ~ 1, \n           model = v_auto$var_model,\n           data = variable_data_sf)\nk\n\n\ndata:\nvar1 : formula = MonthlyValue`~`1 ; data dim = 11 x 4\nvariograms:\n        model     psill    range\nvar1[1]   Nug 1491.0299    0.000\nvar1[2]   Exp  693.4758 8155.059\n\n\nshow code\n# estimate the unknown grids\nresp &lt;- predict(k, coop)\n\n\n[using ordinary kriging]\n\n\nshow code\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\nresp$pred &lt;- resp$pred\n\n# create a raster surface data object\nkpred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\")\n\n# map the interpolated variable raster, kpred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nData Prep:\n\n\nCode\n# Indicate user variable\nselected_var &lt;- \"Mean Temperature (°C)\" # \"Daily Rainfall Total (mm)\" or \"Mean Temperature (°C)\"\nselected_month &lt;- c(\"February\") # User to specify Month\nselected_year &lt;- c(\"2023\") # User to specify Year\ninterpolation_method &lt;- \"IDW\"\n\n# Create table for chosen variable and time period\nvariable_data &lt;- weather_data %&gt;%\n  filter(Year %in% selected_year,\n         Month_Name %in% selected_month) %&gt;%\n  group_by(Station, Year, Month, LAT, LONG) %&gt;%\n  summarise(MonthlyValue = if(grepl(\"Rainfall\", selected_var)) {\n                sum(.data[[selected_var]], na.rm = TRUE) # aggregate by computing sum of rainfall for the month. \n              } else if (grepl(\"Temperature\", selected_var)) {\n                mean(.data[[selected_var]], na.rm = TRUE) # aggregate by computing average temperature per month.\n              }, .groups = 'drop')\n  \n# Make it spatial data\nvariable_data_sf &lt;- st_as_sf(variable_data, \n                      coords = c(\"LONG\", # X axis \n                                 \"LAT\"), # Y axis\n                      crs= 4326) %&gt;%\n  st_transform(crs = 3414) # To project this into SVY21\n\n# Create grid data object / Raster data\n# Extract bounding box variables from mpsz2019 \nbbox &lt;- as.list(st_bbox(mpsz2019))\n\n# Assume user is able to indicate resolution\nres = 50 # User Input. The smaller the value the higher the resolution, but the higher the computational requirement (slower processing).\nnrows =  (bbox$ymax - bbox$ymin)/res\nncols = (bbox$xmax - bbox$xmin)/res\n# Create a raster layer, `grid`,  from an existing spatial object `mpsz2019`\ngrid &lt;- terra::rast(mpsz2019, \n                   nrows = nrows, \n                   ncols = ncols)\n# Generate coordinates for each cell of the raster \nxy &lt;- terra::xyFromCell(grid,\n                         1:ncell(grid))\n# Converting coordinates of raster into a spatial (sf) object\ncoop &lt;- st_as_sf(as.data.frame(xy),\n                 coords = c(\"x\",\"y\"),\n                 crs = st_crs(mpsz2019)) # Assign CRS based on mpsz2019\ncoop &lt;- st_filter(coop, mpsz2019) # Filter to only only includes points within mpsz2019\n\n\nAuto fit variogram:\n\n\nshow code\nv_auto &lt;- autofitVariogram(MonthlyValue ~ 1, \n                           variable_data_sf)\nplot(v_auto)\n\n\n\n\n\n\n\n\n\nshow code\nv_auto\n\n\n$exp_var\n  np      dist      gamma dir.hor dir.ver   id\n1 11  7150.576 0.09705995       0       0 var1\n2  5 11075.718 0.15026786       0       0 var1\n3 11 13965.947 0.10373724       0       0 var1\n\n$var_model\n  model     psill    range kappa\n1   Nug 0.0000000    0.000     0\n2   Ste 0.1224051 5662.722     5\n\n$sserr\n[1] 5.990056e-11\n\nattr(,\"class\")\n[1] \"autofitVariogram\" \"list\"            \n\n\nFinal surface map:\n\n\nshow code\n# perform spatial interpolation by using the newly derived model \nk &lt;- gstat(formula = MonthlyValue ~ 1, \n           model = v_auto$var_model,\n           data = variable_data_sf)\nk\n\n\ndata:\nvar1 : formula = MonthlyValue`~`1 ; data dim = 11 x 4\nvariograms:\n        model     psill    range kappa\nvar1[1]   Nug 0.0000000    0.000     0\nvar1[2]   Ste 0.1224051 5662.722     5\n\n\nshow code\n# estimate the unknown grids\nresp &lt;- predict(k, coop)\n\n\n[using ordinary kriging]\n\n\nshow code\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\nresp$pred &lt;- resp$pred\n\n# create a raster surface data object\nkpred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\")\n\n# map the interpolated variable raster, kpred\nmain_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Distribution for Total Rainfall (mm) for\", selected_month, selected_year),\n                paste(\"Distribution for Average Mean Temperature (°C) for\", selected_month, selected_year))\nraster_title &lt;- ifelse(selected_var == \"Daily Rainfall Total (mm)\",\n                paste(\"Total Monthly Rainfall (mm)\"),\n                paste(\"Average Mean Temperature (°C)\"))\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\ntm_shape(kpred) + \n  tm_raster(alpha = 0.6, \n            palette = \"viridis\",\n            title = raster_title) +\n  tm_layout(main.title = main_title,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#ui-design",
    "href": "Take-home_Ex/Take-home_Ex4/Take-home_Ex4.html#ui-design",
    "title": "Take-home Exercise 4 (Work in Progress)",
    "section": "4.2 UI Design",
    "text": "4.2 UI Design\nIn this section we will describe the parameters to expose, the output to show, while suggesting the Shiny UI components to use.\n\n4.2.1 Parameters to expose\nThe parameters to be exposed can be categorised into 2 types.\n\nData Selection Parameters:\n\n\nVariable Selection: Single select option to choose between the variables to analyse (Daily Rainfall Total (mm), Mean Temperature (°C))\nTime Window Selection: Single select option for temporal resolution for analysis (Daily, Monthly, Quarterly, Yearly intervals).\n\n\nModel Parameters for Spatial Interpolation:\n\nFor both methods: Choose resolution\nIDW: nmax\n4.3 Ordinary Kriging:\n\n\n\n\n4.3.1 Output\n\n\n4.3.2 \nDesign considerations for user control:\n\nUse radioButtons function to select only one variable\nUse radioButtons function to select only one type of time window\nDisplay original data and both methods for interpolation side by side.\nFor each method, offer variable to tweak:\nInverse Distance Weighting (IDW): nmax\nOrdinary Kriging"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex9/In-class_Ex9.html",
    "href": "In-class_Ex/In-class_Ex9/In-class_Ex9.html",
    "title": "In-class Exercise 8",
    "section": "",
    "text": "To visualize and analyse network data, using R and appropriate R packages."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#overview",
    "href": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#overview",
    "title": "In-class Exercise 8",
    "section": "",
    "text": "To visualize and analyse network data, using R and appropriate R packages."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#load-libraries",
    "href": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#load-libraries",
    "title": "In-class Exercise 8",
    "section": "Load libraries",
    "text": "Load libraries\n\npacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, \n               clock, # only for time\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#import-data",
    "href": "In-class_Ex/In-class_Ex9/In-class_Ex9.html#import-data",
    "title": "In-class Exercise 8",
    "section": "Import data",
    "text": "Import data\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\nTransform SentDate column to Date type and create a new Weekday column:\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(Weekday = wday(SentDate, # Create new column , Weekday\n                        label = TRUE,\n                        abbr = FALSE)) %&gt;%\n  mutate(SendDate = dmy(SentDate))  # Change type to date and create a new column, Senddate\n\nAggregate the individual by date, senders, receivers, main subject and day of the week:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;% # Focus only on rows that are 'Work related'\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;% # Add new field, Weight. Assigned based on summarise function..?\n  filter(source!=target) %&gt;% # Exclude emails where recipient and sender are the same. \n  filter(Weight &gt; 1) %&gt;% \n  ungroup()\n\nUse tbl_graph() to build tidygraph data model:\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes, edges = GAStech_edges_aggregated, directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\nPlot basic network graph:\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\nTry tweaking the layout as per this documentation.\n\ng &lt;- ggraph(GAStech_graph,\n            layout = \"kk\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph,\n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\ng &lt;-ggraph(GAStech_graph,\n           layout = \"nicely\") +\n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 3)\n\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\nAnalysis: Computing centrality indices:\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()"
  }
]