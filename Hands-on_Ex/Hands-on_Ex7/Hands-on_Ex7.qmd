---
title: "Hands-on Exercise 7 (Work in Progress)"
subtitle: "Visualising and Analysing Geographic Data"
date: February 25, 2024
date-modified: "last-modified"
format:
  html:
    toc: true
    number-sections: true
    code-line-numbers: true
    
execute: 
  eval: true
  echo: true
  warning: false  
---

# **Choropleth Mapping with R**

## Overview

In this exercise I will learn how to plot functional and truthful choropleth maps by using an R package called [**tmap**](https://cran.r-project.org/web/packages/tmap/) package.

## Loading libraries

We will use the [**tmap**](https://cran.r-project.org/web/packages/tmap/) package that can create thematic maps, such as choropleths and bubble maps; and the [**sf**](https://cran.r-project.org/web/packages/sf/) package for handling geospatial data.

```{r}
pacman::p_load(sf, tmap, tidyverse)
```

## Importing data

Two data set will be used to create the choropleth map. They are:

-   Master Plan 2014 Subzone Boundary (Web) (i.e. `MP14_SUBZONE_WEB_PL`) in ESRI shapefile format. It can be downloaded at [data.gov.sg](https://data.gov.sg/) This is a **geospatial data**. It consists of the **geographical boundary of Singapore at the planning subzone level**. The data is based on URA Master Plan 2014.

-   Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. `respopagesextod2011to2020.csv`). This is an aspatial data fie. It can be downloaded at [Department of Statistics, Singapore](https://www.singstat.gov.sg/) Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to `MP14_SUBZONE_WEB_PL` shapefile.

### **Importing Geospatial Data into R**

We first use the *st_read()* function of **sf** package to import `MP14_SUBZONE_WEB_PL` shapefile into R as a simple feature data frame called `mpsz`.

```{r}
mpsz <- st_read(dsn = "data/geospatial", 
                layer = "MP14_SUBZONE_WEB_PL")
```

::: callout-note
### Student's Notes

There are 323 features (rows) and 15 fields (columns).
:::

Let's examine the content and first ten records of `mpsz:`

```{r}
mpsz
```

::: callout-note
### Student's Notes

Each feature could represent a different area, like a subzone or district. Alongside spatial information, each feature has 15 additional attributes or fields. These fields contain non-spatial data associated with each feature, such as names, codes, and other identifiers.

Geometry type: MULTIPOLYGON: Each feature's geometry is stored as a MULTIPOLYGON, indicating that the spatial data for each area consists of one or more polygons. A polygon is a shape enclosed by a boundary that defines the area of the feature. MULTIPOLYGONs are used for complex shapes that might consist of several disjointed parts.

Dimension: XY This indicates that the spatial data is in two dimensions, using X and Y coordinates to represent locations on a plane. This is typical for most mapping and GIS applications.

Bounding box: xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33 The bounding box gives you the minimum and maximum coordinates of the dataset in the X (longitude) and Y (latitude) dimensions. This provides a rough idea of the spatial extent covered by your data.

Projected CRS: SVY21 The Coordinate Reference System defines how the two-dimensional, flat map relates to real places on the Earth. SVY21 is a specific type of CRS that is likely tailored for a particular region e.g. Singapore.
:::

### **Importing Attribute Data into R**

Next, we will import *respopagsex2011to2020.csv* file into RStudio and save the file into an R dataframe called *popagsex*.

```{r}
popdata <- read_csv("data/aspatial/respopagesextod2011to2020.csv")
```

```{r}
str(popdata)
```

::: callout-note
### Student's Notes

Data consists of 984,656 rows and 7 columns.

Recall that PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile. It seems like

-   *PA* corresponds to *PLN_AREA_N*
-   *SZ* corresponds to *SUBZONE_N*

PA: Area / Region in SG SZ: Specific area within PA AG: Age group Sex: Gender TOD: Type of Dwelling Pop: Population for this age group for this area and TOD. Time: Year of info
:::

### **Data Preparation**

We first need to prepare a data table with year **2020** values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.

-   YOUNG: age group 0 to 4 until age group 20 to 24,

-   ECONOMY ACTIVE: age group 25-29 until age group 60-64,

-   AGED: age group 65 and above,

-   TOTAL: all age group, and

-   DEPENDENCY: the ratio between young and aged against economy active group

#### Data wrangling

The following data wrangling and transformation functions will be used:

-   *pivot_wider()* of **tidyr** package, and

-   *mutate()*, *filter()*, *group_by()* and *select()* of **dplyr** package

```{r}
popdata2020 <- popdata %>%
  filter(Time == 2020) %>% # Filter data for year 2020
  group_by(PA, SZ, AG) %>% # Group by PA SZ and AG. Not grouped: Sex , TOD. So we will see sum of age across each TOD and Gender for group. 
  summarise(`POP` = sum(`Pop`)) %>% # Allows us to see population for each of the group, adding up for all type of TOD and Gender. 
  ungroup() %>% 
  pivot_wider(names_from=AG, 
              values_from=POP) %>% # One row per combi of PA and SZ. Add columns for the Age Groups. Each value is the sum Pop for that age group. 
  mutate(YOUNG = rowSums(.[3:6]) # Create new column YOUNG that calculates sum of values in columns 3 to 6 for each row. The . notation is a placeholder that refers to the current data frame being manipulated. 
         +rowSums(.[12])) %>% # This is age group 5-9 which has weird position in column 12. 
mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+ # Create new col again 
rowSums(.[13:15]))%>%
mutate(`AGED`=rowSums(.[16:21])) %>%  # Create new col again 
mutate(`TOTAL`=rowSums(.[3:21])) %>%  # Create new col again but sum across all age groups
mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) # New col for the ratio between young and aged against economy active group
/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, # Used to only select relevant cols so all the age Group cols are dropped. 
       `ECONOMY ACTIVE`, `AGED`, 
       `TOTAL`, `DEPENDENCY`)
```

#### Joining the attribute data and geospatial data

Before we can perform the georelational join, one extra step is required to **convert the values in PA and SZ fields to uppercase**. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.

```{r}
# popdata2020 <- popdata2020 %>%
#   mutate_at(.vars = vars(PA, SZ),  # .vars argument specifies the variables (or columns) on which the function specified by .funs will be applied. 
#           .funs = funs(toupper)) %>% # .funs argument specifies the function(s) to apply to the selected variables. toupper function will be applied to each of the selected variables.
#   filter(`ECONOMY ACTIVE` > 0) # only include those where the value of the ECONOMY ACTIVE column is greater than 0.

# As `funs()` was deprecated in dplyr 0.8.0, we will use this
popdata2020 <- popdata2020 %>%
  mutate(across(.cols = c(PA, SZ), .fns = toupper)) %>%
  filter(`ECONOMY ACTIVE` > 0)
```

Next, *left_join()* of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. *SUBZONE_N* and *SZ* as the common identifier.

```{r}
mpsz_pop2020 <- left_join(mpsz, popdata2020,
                          by = c("SUBZONE_N" = "SZ"))
```

::: callout-note
### Student's Notes

There is no more *SZ* column in the dataframe *mpsz_pop2020*.

If the *popdata2020* data does not have a specified SZ that corresponds to SUBZONE_N, the values for PA, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY columns will reflect as NA.
:::

Save output to .rds:

```{r}
write_rds(mpsz_pop2020, "data/rds/mpszpop2020.rds")
```

### Choropleth Mapping Geospatial Data Using tmap

Two approaches can be used to prepare thematic map using *tmap*, they are:

-   Plotting a thematic map quickly by using *qtm()*.

-   Plotting highly customisable thematic map by using tmap elements.

#### Plotting a choropleth map quickly by using *qtm()*

The easiest and quickest to draw a choropleth map using **tmap** is using *qtm()*. It is concise and provides a good default visualisation in many cases.

The code chunk below will draw a cartographic standard choropleth map as shown below.

```{r}
tmap_mode("plot") # Set the tmap mode: "plot" or "view"
qtm(mpsz_pop2020, # qtm is a quick plotting method to Plot a thematic map
    fill = "DEPENDENCY") # either a color to fill the polygons, or name of the data variable in shp to draw a choropleth. Only applicable when shp contains polygons.  Set fill = NULL to draw only polygon borders. 
```

```{r}
tmap_mode("plot")  
qtm(mpsz_pop2020,
    fill = NULL) # Set fill = NULL to draw only polygon borders. 
```

Things to learn from the code chunk above:

-   *tmap_mode()* with “plot” option is used to produce a **static map**.

    -   For interactive mode, “view” option should be used. If the mode is set to "view", the map is shown interactively as an htmlwidget. However it does not work for this data.

-   *fill* argument is used to map the attribute (i.e. DEPENDENCY)\

#### **Creating a choropleth map by using *tmap*’s elements**

Despite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of *qtm()* is that it makes aesthetics of individual layers harder to control.

To draw a high quality cartographic choropleth map as shown in the figure below, **tmap**’s drawing elements should be used.

```{r}
tm_shape(mpsz_pop2020)+ # Creates a tmap-element that specifies a spatial data object, which we refer to as shape. Also the projection and covered area (bounding box) can be set. It is possible to use multiple shape objects within one plot (see tmap-element).
  tm_fill("DEPENDENCY",  # AES Layer. Create a polygon layer (without borders)
          style = "quantile",  #  define a data classification method. 
          palette = "Blues",
          title = "Dependency ratio") +
  tm_layout(main.title = "Distribution of Dependency Ratio by planning subzone", # layout element. Adjust the layout (main function)
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) + # AES Layer. Create polygon borders.
  tm_compass(type="8star", size = 2) + #Attribute. Create a map compass
  tm_scale_bar() + # Attribute. Create a scale bar
  tm_grid(alpha =0.2) + # Attribute. Create grid lines
  tm_credits("Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\n and Population data from Department of Statistics DOS", 
             position = c("left", "bottom")) # Attribute. Create a text for credits
```

::: callout-note
## Student's Notes

Trying *tm_facets()* wil argument along set to "SUBZONE_N" created a lot of plots with each plot being a specified area.
:::

#### Drawing a base map

The basic building block of **tmap** is *tm_shape()*, followed by one or more layer elements such as *tm_fill()* and *tm_polygons()*.

In the code chunk below, *tm_shape()* is used to define the input data (i.e *mpsz_pop2020*) and *tm_polygons()* is used to draw the planning subzone polygons.

```{r}
tm_shape(mpsz_pop2020) +
  tm_polygons()
```

#### Drawing a choropleth map using *tm_polygons()*

To draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as *Dependency* to the aes layer *tm_polygons()*.

```{r}
tm_shape(mpsz_pop2020)+
  tm_polygons("DEPENDENCY")
```

Things to learn from *tm_polygons()*:

-   The default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by **tmap** will be provided later on.

-   The default colour scheme used is `YlOrRd` of ColorBrewer. You will learn more about the color scheme later on

-   By default, missing values will be shaded in grey.

#### Drawing a choropleth map using *tm_fill()* and *tm_border()*

**Actually, *tm_polygons()* is a wrapper of *tm_fill()* and *tm_border()*.**

*tm_fill()* [shades]{.underline} the polygons by using the default colour scheme and *tm_borders()* adds the [borders]{.underline} of the shapefile onto the choropleth map.

The code chunk below draws a choropleth map by using *tm_fill()* alone.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY")
```

Notice that the planning subzones are shared according to the respective dependecy values

To add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY") +
  tm_borders(lwd = 0.1,  alpha = 1)
```

Notice that light-gray border lines have been added on the choropleth map.

-   The *alpha* argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).

Beside *alpha* argument, there are three other arguments for *tm_borders()*, they are:

-   *col* = border colour,

-   *lwd* = border line width. The default is 1, and

-   *lty* = border line type. The default is “solid".

### **Data classification methods of tmap**

Most choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and [group them into data ranges or classes.]{.underline}

**tmap** provides a total ten data classification methods, namely: *fixed*, *sd*, *equal*, *pretty* (default), *quantile*, *kmeans*, *hclust*, *bclust*, *fisher*, and *jenks*.

To define a data classification method, the *style* argument of *tm_fill()* or *tm_polygons()* will be used.

::: callout-note
## Student's Notes

From documentation on *style*

This is a method to process the color scale when col is a [numeric variable]{.underline}.

Discrete gradient options are "cat", "fixed", "sd", "equal", "pretty", "quantile", "kmeans", "hclust", "bclust", "fisher", "jenks", "dpih", "headtails", and "log10_pretty".

A numeric variable is processed as a categorical variable when using "cat", i.e. each unique value will correspond to a distinct category.
For the other discrete gradient options (except "log10_pretty"), see the details in classIntervals (extra arguments can be passed on via style.args).
Continuous gradient options are "cont", "order", and "log10". The first maps
the values of col to a smooth gradient, the second maps the order of values
of col to a smooth gradient, and the third uses a logarithmic transformation.
:::

More on some of the styles from [classIntervals](https://www.rdocumentation.org/packages/classInt/versions/0.4-10/topics/classIntervals):

-   The "equal" style divides the range of the variable into n parts.

-   The "pretty" style chooses a number of breaks not necessarily equal to n using **`pretty`**, but likely to be legible; arguments to **`pretty`** may be passed through **`...`**.

-   The "quantile" style provides quantile breaks; arguments to **`quantile`** may be passed through **`...`**.

-   The "kmeans" style uses **`kmeans`** to generate the breaks; it may be anchored using **`set.seed`**; the **`pars`** attribute returns the kmeans object generated; if **`kmeans`** fails, a jittered input vector containing **`rtimes`** replications of **`var`** is tried --- with few unique values in **`var`**, this can prove necessary; arguments to **`kmeans`** may be passed through **`...`**.

-   The "hclust" style uses **`hclust`** to generate the breaks using hierarchical clustering; the **`pars`** attribute returns the hclust object generated, and can be used to find other breaks using **`getHclustClassIntervals`**; arguments to **`hclust`** may be passed through **`...`**.

-   The "bclust" style uses **`bclust`** to generate the breaks using bagged clustering; it may be anchored using **`set.seed`**; the **`pars`** attribute returns the bclust object generated, and can be used to find other breaks using **`getBclustClassIntervals`**; if **`bclust`** fails, a jittered input vector containing **`rtimes`** replications of **`var`** is tried --- with few unique values in **`var`**, this can prove necessary; arguments to **`bclust`** may be passed through **`...`**.

-   The "fisher" style uses the algorithm proposed by W. D. Fisher (1958) and discussed by Slocum et al. (2005) as the Fisher-Jenks algorithm; added here thanks to Hisaji Ono. This style will subsample by default for more than 3000 observations. This style should always be preferred to "jenks" as it uses the original Fortran code and runs nested for-loops much faster.

-   The "jenks" style has been ported from Jenks' code, and has been checked for consistency with ArcView, ArcGIS, and MapInfo (with some remaining differences); added here thanks to Hisaji Ono (originally reported as Basic, now seen as Fortran (as described in a talk last seen at http://www.irlogi.ie/wp-content/uploads/2016/11/NUIM_ChoroHarmful.pdf, slides 26-27)). Note that the sense of interval closure is reversed from the other styles, and in this implementation has to be right-closed - use cutlabels=TRUE in **`findColours`** on the object returned to show the closure clearly, and use **`findCols`** to extract the classes for each value. This style will subsample by default for more than 3000 observations.

-   The "dpih" style uses the **`dpih()`** function from KernSmooth (Wand, 1995) implementing direct plug-in methodology to select the bin width of a histogram.

-   The "headtails" style uses the algorithm proposed by Bin Jiang (2013), in order to find groupings or hierarchy for data with a heavy-tailed distribution. This classification scheme partitions all of the data values around the mean into two parts and continues the process iteratively for the values (above the mean) in the head until the head part values are no longer heavy-tailed distributed. Thus, the number of classes and the class intervals are both naturally determined. By default the algorithm uses **`thr = 0.4`**, meaning that when the head represents more than 40% of the observations the distribution is not considered heavy-tailed.

#### Plotting choropleth maps with built-in classification methods

The code chunk below shows a quantile data classification that uses 5 classes.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5)
```

In the code chunk below, *equal* data classification method is used. Notice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "equal") + # divides the range of the variable into 5 parts
  tm_borders(alpha = 0.5)
```

> **Warning: Maps Lie!**

> DIY: Using what you havelearned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.

-   pretty

    -   Seems similar to equal method

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "pretty") +
  tm_borders(alpha = 0.5)
```

-   kmeans

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "kmeans") +
  tm_borders(alpha = 0.5)
```

-   hclust

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "hclust") +
  tm_borders(alpha = 0.5)
```

> DIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?

-   n = 5

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5)
```

-   n = 4

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 4,
          style = "quantile") +
  tm_borders(alpha = 0.5)
```

-   n = 3

```{r}
tm_shape(mpsz_pop2020)+
  tm_fill("DEPENDENCY",
          n = 3,
          style = "quantile") +
  tm_borders(alpha = 0.5)
```

#### Plotting choropleth map with custom break

For all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the *breaks* argument to the *tm_fill()*. It is important to note that, in **tmap** the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the *breaks* option (the values must be in increasing order).

Before we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of **DEPENDENCY** field.

# References

-   [**R for Visual Analytics: Choropleth Mapping with R**](https://r4va.netlify.app/chap21)
